## Anomal-IA, herramienta para detecciÃ³n de anomalÃ­as para ElectroDunas

Yolanda Franco
Daniel Rozo
JosÃ© Hoyos
Gabriel GÃ³mez

Este proyecto trata sobre la identificaciÃ³n de anomalÃ­as en el consumo de energÃ­a elÃ©ctrica para diferentes clientes de ElectroDunas.

### Tratamiento previo de los datos: 
#### Rutina de carga de informaciÃ³n: 
En una primera etapa del proceso, se estableciÃ³ una estructura de almacenamiento inicial para los datos de los clientes, a travÃ©s de la creaciÃ³n de una carpeta designada. Esta carpeta sirve como un repositorio provisional donde se alojarÃ¡n los archivos .csv que contienen informaciÃ³n relevante sobre los consumos y comportamientos de los clientes. Se anticipa que este mÃ©todo de almacenamiento serÃ¡ reemplazado por un repositorio mÃ¡s sofisticado y dinÃ¡mico en el futuro, especialmente si se logra acceder a los datos de los clientes en tiempo real. 
 
Los datos de los clientes se organizaron y manipularon utilizando el lenguaje de programaciÃ³n Python, aprovechando la potencia de las bibliotecas especializadas como Pandas. La informaciÃ³n se cargÃ³ en memoria como una serie de dataframes (DF). Cada DF corresponde a un archivo .csv individual, representando los datos asociados a un cliente especÃ­fico. AdemÃ¡s de la informaciÃ³n de consumo, se enriqueciÃ³ cada DF agregando una columna que identifica el sector econÃ³mico al que pertenece el cliente correspondiente. 
 
AsÃ­, se procediÃ³ a unir la informaciÃ³n proporcionada por la empresa sobre los sectores econÃ³micos de los clientes. Esto se realizÃ³ mediante la incorporaciÃ³n de un archivo externo en formato Excel que contiene la clasificaciÃ³n de los clientes segÃºn sus respectivos sectores econÃ³micos. Se realizaron ajustes pertinentes en los nombres de las columnas y en el formato de los datos para asegurar una integraciÃ³n sin fisuras entre los datos de los clientes y la informaciÃ³n sobre sus sectores econÃ³micos. 
 
#### Descriptivos: 
Para analizar la informaciÃ³n proporcionada por el cliente, llevamos a cabo varios anÃ¡lisis descriptivos. Realizamos una evaluaciÃ³n grÃ¡fica para examinar los patrones de comportamiento mensual de los clientes en cada sector. Sin embargo, debido a las limitaciones de espacio en este documento, nuestro anÃ¡lisis descriptivo se centrarÃ¡ en una visiÃ³n global de los datos. El objetivo de este anÃ¡lisis es identificar patrones de consumo y familiarizarnos con la informaciÃ³n proporcionada. 

En un primer anÃ¡lisis, vamos a evaluar la correlaciÃ³n de las variables EnergÃ­a Activa, Reactiva y Voltaje FA y FC. Esto nos permite comprender las relaciones entre diferentes variables en un conjunto de datos, facilitando tanto la reducciÃ³n de la dimensionalidad como la identificaciÃ³n de anomalÃ­as. Por ejemplo, si dos variables suelen estar altamente correlacionadas y observamos un punto donde una variable se desvÃ­a significativamente de esta relaciÃ³n habitual, esto podrÃ­a indicar la presencia de una anomalÃ­a.  

La correlaciÃ³n entre las variables Voltaje_FA y Voltaje_FC es fuerte (0.95), lo que indica que suelen moverse juntas. Un punto donde una de estas variables se desvÃ­a significativamente de esta tendencia podrÃ­a indicar una anomalÃ­a. Por otro lado, la correlaciÃ³n moderada (0.64) entre la energÃ­a activa y la energÃ­a reactiva sugiere una relaciÃ³n positiva menos fuerte. Aun asÃ­, un punto donde la energÃ­a activa es alta pero la energÃ­a reactiva es baja (o viceversa) podrÃ­a ser un indicador de anomalÃ­a (imagen 1). 

![Imagen 1](https://github.com/ggomez1803/ElectroDunas/assets/10146054/8439316a-b445-4839-ba6b-f3bd9000a405)<br>
Imagen 1. Matriz de correlaciÃ³n de variables EnergÃ­a Activa â€“ Reactiva y Voltaje FA y FC 
 
Para obtener una visiÃ³n general de la distribuciÃ³n de los datos y tener alguna nociÃ³n sobre las anomalÃ­as, se generaron grÃ¡ficos de boxplot. A partir de este anÃ¡lisis, se concluye que hay una gran heterogeneidad y datos anÃ³malos en los patrones de consumo de energÃ­a elÃ©ctrica. AdemÃ¡s, se observan anomalÃ­as en los datos de voltaje, aunque estas son menos frecuentes en comparaciÃ³n con el par energÃ©tico. 

 ![Imagen 2](https://github.com/ggomez1803/ElectroDunas/assets/10146054/190b1907-fb06-4a71-9bb8-5f598e702f1b)<br>
Imagen 2. Boxplots por cliente y sector econÃ³mico 
DespuÃ©s de investigar y consultar expertos en la materia, experimentamos con dos conceptos que no solo definirÃ­an nuestro rumbo a seguir en la detecciÃ³n de anomalÃ­as en nuestro sistema, sino que tambiÃ©n nos ayudarÃ­an a reducir la dimensionalidad a solo 2 variables, explicando las 4 dadas. El factor de potencia (FP), es una medida de eficiencia en la trasferencia de energÃ­a elÃ©ctrica, se define como la relaciÃ³n entre la energÃ­a activa y la potencia aparente. La energÃ­a activa, como sabemos, es la que se consume realmente al realizar algÃºn trabajo Ãºtil, como encender una bombilla. La potencia aparente, un tÃ©rmino nuevo para el experimento, se puede entender como la potencia total que fluye en un circuito incluyendo energÃ­a activa y reactiva. Esta la definiremos en la siguiente fÃ³rmula: 

$\ S = âˆš{PË†2} + QË†2$
 
Donde: <br>
- S es la potencia aparente
- P es la energÃ­a activa.
- Q es la energÃ­a reactiva. 
 
Teniendo clara esta mediciÃ³n, el FP se calcula dividiendo la energÃ­a activa (P) por la potencia aparente (S). La definiremos en la siguiente fÃ³rmula: 

$\ FP = P/S$

Donde: <br>
- P es la energÃ­a activa.
- S es la potencia aparente. 
 
El factor de potencia (FP) debe ser un valor entre 0 y 1. Idealmente, cuando este valor se aproxima a 1, indica que la energÃ­a se estÃ¡ utilizando de manera eficiente. Esto nos lleva a un supuesto importante: un sistema eficiente deberÃ­a tener un factor de potencia cercano a este valor. Si el factor de potencia se aleja significativamente de 1, podrÃ­a indicar una anomalÃ­a. Esto se debe a que un factor de potencia bajo sugiere que una cantidad significativa de energÃ­a se estÃ¡ perdiendo durante el proceso de transferencia de energÃ­a. 

Por otro lado, cuando consideramos las dos variables Voltaje_FA y Voltaje_FC, podemos inferir que estamos tratando con un sistema trifÃ¡sico (ST). Un ST es un sistema de producciÃ³n, distribuciÃ³n y consumo de energÃ­a elÃ©ctrica que utiliza tres corrientes monofÃ¡sicas. En un sistema trifÃ¡sico equilibrado, los voltajes FA, FB y FC deberÃ­an tener magnitudes iguales y estar desfasados simÃ©tricamente. Si este equilibrio no se mantiene, podemos inferir que el sistema de tensiones estÃ¡ desequilibrado.1 

Considerando que sÃ³lo disponemos de los voltajes FA y FC, empleamos una fÃ³rmula que proporciona una medida normalizada del principio de desequilibrio. Esta fÃ³rmula consiste en dividir la diferencia absoluta entre los voltajes FA y FC por el voltaje mÃ¡s pequeÃ±o. De esta manera, obtenemos una medida de desequilibrio que es independiente de la magnitud de los voltajes. Este enfoque es especialmente Ãºtil para identificar anomalÃ­as dado que, en un sistema trifÃ¡sico equilibrado, los tres voltajes deberÃ­an ser iguales. Por lo tanto, cualquier desviaciÃ³n significativa de esta igualdad podrÃ­a indicar un problema o anomalÃ­a en el sistema. 

$\ ğ·ğ‘‰= (âˆ£ğ‘‰ğ¹ğ´âˆ’ğ‘‰ğ¹ğ¶âˆ£)/min(ğ‘‰ğ¹ğ´,  ğ‘‰ğ¹ğ¶)$

 
Donde: <br>
- DV es el desequilibrio de voltaje normalizado.
- ğ‘‰ğ¹ğ´ es la variable Voltaje_FA.
- ğ‘‰ğ¹ğ¶ es la variable Voltaje_FC. 
 
La obtenciÃ³n del factor de potencia (FP) y el desequilibrio de voltaje (DV) nos proporciona dos variables normalizadas que nos permiten explicar tanto las energÃ­as como los voltajes en nuestro experimento de manera eficiente. 
 
En la imagen 3, se muestran las correlaciones obtenidas para las diferentes variables disponibles. Con relaciÃ³n a nuestras nuevas variables, observamos una correlaciÃ³n positiva entre el factor de potencia (FP) y la energÃ­a activa, lo que podrÃ­a indicar que las anomalÃ­as estÃ¡n asociadas con una eficiencia energÃ©tica reducida. De manera similar, las correlaciones negativas entre el desequilibrio de voltaje y los voltajes FA y FC podrÃ­an indicar que las anomalÃ­as estÃ¡n asociadas con un sistema desequilibrado. 

 ![Imagen 3](https://github.com/ggomez1803/ElectroDunas/assets/10146054/4d40c53a-7da9-4c91-8467-cbb246683813)<br>
Imagen 3. Matriz de correlaciÃ³n con las variables FP y DV. 

### Preprocesamiento: 
A cada uno de los dataframes (DF) pertenecientes a la lista creada previamente con la informaciÃ³n de los clientes se agregaron las columnas de Factor Potencia (FP), Potencia Aparente (S) y Desequilibrio de voltaje (DV). De igual manera, se agregÃ³ la columna de fecha, se validÃ³ que no hubiera datos faltantes, que todos los DFs tuvieran el mismo nÃºmero de columnas y por Ãºltimo que la fecha estuviera en el mismo formato. Al final se consolidÃ³ todo en una DF global. Ver imagen 4. 

 ![Imagen 4](https://github.com/ggomez1803/ElectroDunas/assets/10146054/cec90ae0-460f-4bbf-9594-69b64752c7d8)<br>
Imagen 4. CÃ³digo preprocesamiento. 
 
Al evaluar el Factor de Potencia (FP) y el Desequilibrio de Voltaje (DV) en una distribuciÃ³n de frecuencias (imagen 6), observamos que los datos tienden a concentrarse en valores con FP = 1 y DV = 0. Sin embargo, en la grÃ¡fica del FP, se observan datos anÃ³malos, como valores negativos, y en el DV, datos extremos que alcanzan hasta 60,000. Para el tratamiento de estos valores atÃ­picos, los mejores resultados se obtuvieron a travÃ©s del Rango Intercuartil, considerando como atÃ­picas las observaciones que se encuentran por encima de 1.5+Q3 o debajo Q1-1.5 veces este valor (imagen 5). TambiÃ©n se probÃ³ la mÃ©trica Z-Score para tratar outliers, pero no proporcionÃ³ los resultados esperados. Como se mencionÃ³ anteriormente, no era conveniente imputar esta informaciÃ³n al principio debido a la naturaleza del experimento de encontrar datos anÃ³malos; sin embargo, dados los resultados, se tomÃ³ la decisiÃ³n de clasificar automÃ¡ticamente como anomalÃ­as los outliers encontrados antes de proceder con los modelos de supervisados de clusterizaciÃ³n. 

 ![Imagen 5](https://github.com/ggomez1803/ElectroDunas/assets/10146054/50783803-a71a-4fb0-9cf8-2e0274754221)<br>
Imagen 5. CÃ³digo para tratar outliers usando IQR por sector. 


![Imagen 6](https://github.com/ggomez1803/ElectroDunas/assets/10146054/86d9bd3a-f538-49ac-b39b-e403bfef1729)<br>
Imagen 6. DistribuciÃ³n de frecuencias Factor de potencia y desequilibrio de voltaje de toda la muestra. 
 
El tratamiento de los outliers se llevÃ³ a cabo considerando el sector al que pertenece cada cliente. Esta consideraciÃ³n es relevante ya que puede proporcionar una medida significativa para identificar valores extremos dentro del entorno en el que opera cada cliente. Tras este tratamiento, la distribuciÃ³n de los datos mostrÃ³ una notable mejora para estas variables, presentando magnitudes con un mayor sentido tÃ©cnico. Los detalles se pueden observar en la siguiente imagen (Imagen 7): 

![Imagen 7](https://github.com/ggomez1803/ElectroDunas/assets/10146054/0f129ffa-d451-469f-ac95-6f2fca5ba390)<br>
Imagen 7. DistribuciÃ³n de frecuencias de FP y DV sin outliers. 

Para preparar los datos para un anÃ¡lisis de clustering subsiguiente, hemos seleccionado las columnas de interÃ©s especÃ­ficas: el Factor de Potencia (FP) y el Desequilibrio de Voltaje (DV). Es importante recordar nuestra hipÃ³tesis de que los datos que se desvÃ­an significativamente de un FP igual a 1 y un DV igual a 0 tienen una mayor probabilidad de ser considerados anomalÃ­as. 
 
#### Entrenamiento de los modelos: 
El objetivo principal de esta etapa del proyecto es explorar y evaluar diversos algoritmos de clustering para segmentar los datos de consumo de energÃ­a de los clientes en dos grupos distintos: consumos normales y consumos atÃ­picos. Dado que el proyecto se enfoca en el anÃ¡lisis no supervisado, no se busca una calibraciÃ³n especÃ­fica de los modelos, sino mÃ¡s bien una evaluaciÃ³n exhaustiva de su desempeÃ±o utilizando mÃ©tricas adecuadas. 
Inicialmente se consideraron varios algoritmos de clustering, entre ellos, K-Means, Birch y Spectral Clustering, cada uno con sus propias caracterÃ­sticas y supuestos subyacentes sobre la estructura de los datos. Sin embargo, basÃ¡ndonos en el supuesto que un sistema elÃ©ctrico Ã³ptimo tiende a que el factor de potencia (FP) sea 1 y el desequilibrio de voltaje (DV) sea 0, decidimos recurrir a probar modelos donde pudiÃ©ramos definir desde un principio el centroide Ã³ptimo (1,0).  
Inicialmente, nos centramos en el algoritmo K-Means (KM). Este algoritmo presenta la ventaja de permitirnos definir nuestro propio centroide, ademÃ¡s de ser fÃ¡cil de implementar y eficiente en tÃ©rminos computacionales. No obstante, dada su naturaleza iterativa del proceso de minimizaciÃ³n de distancias, no hay garantÃ­a que los centroides permanezcan en la posiciÃ³n Ã³ptima que buscamos. Es decir, los centroides inicializados en (1, 0) con KM pueden desplazarse durante la ejecuciÃ³n del algoritmo. Tras evaluar estas limitaciones, decidimos tambiÃ©n explorar una estrategia alternativa basada en la clasificaciÃ³n por distancia o umbrales. 
En la metodologÃ­a que empleamos basada en modelos con umbrales, calculamos la distancia euclidiana de cada punto al centroide (1, 0). Luego, clasificamos los puntos en dos grupos dependiendo de si su distancia es mayor o menor que la mediana de todas las distancias. AdemÃ¡s, implementamos un enfoque complementario que utiliza la distancia de Mahalanobis. Este enfoque tiene en cuenta la correlaciÃ³n entre las variables y la variabilidad de cada una. BasÃ¡ndonos en un umbral derivado del cuantil de la distribuciÃ³n chi-cuadrado con un nivel de significancia del 0.01, clasificamos los puntos como anomalÃ­as o normales. Esto nos proporciona un 99% de confianza en la precisiÃ³n de la clasificaciÃ³n. 
Durante el proceso de evaluaciÃ³n, utilizamos tres mÃ©tricas de desempeÃ±o ampliamente reconocidas en el Ã¡mbito del clustering: Silhouette score, Davies Bouldin y Calinski Harabasz. Estas mÃ©tricas proporcionan informaciÃ³n valiosa sobre la calidad y la coherencia de los grupos generados por los algoritmos de clustering. Sin embargo, dada la naturaleza de nuestro experimento de encontrar anomalÃ­as, decidimos emplear mÃ©tricas complementarias como la densidad, nÃºmero de datos y varianza, los cuales se profundizarÃ¡n en la secciÃ³n de anÃ¡lisis de resultados. 
Por ejemplo, el Silhouette score, el Ã­ndice de Davies-Bouldin y el Ã­ndice de Calinski-Harabasz nos ayudan a medir la cohesiÃ³n y separaciÃ³n de los clusters, asÃ­ como la dispersiÃ³n dentro y entre ellos. En cuanto a la detecciÃ³n de anomalÃ­as, consideramos la densidad de datos, el nÃºmero de datos y la varianza dentro de un agrupamiento. Un cluster con una densidad de datos baja, un nÃºmero de datos atÃ­pico o una alta varianza puede indicar la presencia de anomalÃ­as. 
Dado que el proyecto tiene como objetivo final la identificaciÃ³n de dos segmentos principales, es decir, consumos normales y consumos atÃ­picos, se ha establecido un nÃºmero de clusters igual a 2 en las pruebas iniciales. Esto simplifica la tarea de evaluaciÃ³n, ya que nos permite comparar directamente la capacidad de cada algoritmo para distinguir estos dos grupos fundamentales. 
 
De esta forma, filtramos el dataframe para incluir solo los valores que no son outliers y basamos el modelo en las columnas de interÃ©s: â€˜Factor_Potencia_%â€™ y â€˜Desequilibrio_Voltaje_%â€™. Recordemos que estas 2 variables ya estÃ¡n estandarizadas. Posteriormente, inicializamos el algoritmo K-Means con dos clusters y centroides especÃ­ficos. Ajustamos el algoritmo K-Means al nuevo dataframe y agregamos las etiquetas de los clusters al dataframe original. En resumen, este cÃ³digo realiza una agrupaciÃ³n K-Means en un conjunto de datos, excluyendo los outliers (imagen 8). 
 
 ![Imagen 8](https://github.com/ggomez1803/ElectroDunas/assets/10146054/921394aa-ba3f-41df-8814-c49f6b7792bc)<br>
Imagen 8. Entrenamiento del modelo K-Means. 
 
 
Para el modelo basado en distancia o umbrales, primero filtramos el dataframe para incluir solo los valores que no son outliers, basÃ¡ndonos en las columnas â€˜Anomalia_FPâ€™ y â€˜Anomalias_Voltajeâ€™. Luego, calculamos la matriz de covarianza inversa de las columnas â€˜Factor_Potencia_%â€™ y â€˜Desequilibrio_Voltaje_%â€™. A continuaciÃ³n, calculamos la distancia de Mahalanobis de cada punto al centroide (1, 0) y la almacenamos en una nueva columna llamada â€˜Distanciaâ€™. Posteriormente, calculamos el cuantil de la distribuciÃ³n chi cuadrado para un nivel de significancia de 0.01, que usamos como umbral para clasificar los puntos segÃºn su distancia de Mahalanobis. Finalmente, los puntos cuya distancia supera la raÃ­z cuadrada del umbral se clasifican como anomalÃ­as pertenecientes al cluster 1, mientras que los demÃ¡s se clasifican como pertenecientes al cluster 0 (imagen 9). 
 
 ![Imagen 9](https://github.com/ggomez1803/ElectroDunas/assets/10146054/5e60ae90-47c5-4582-8655-c710b9e3d187)<br>
Imagen 9. Entrenamiento del modelo basado en umbrales usando distancia de Mahalanobis. 
La distancia de Mahalanobis es preferible en situaciones donde las variables no son independientes o tienen diferentes variabilidades. A diferencia de la distancia euclidiana, que puede inflar las distancias en presencia de alta correlaciÃ³n entre variables, la distancia de Mahalanobis proporciona una medida mÃ¡s precisa al tener en cuenta estas correlaciones. AdemÃ¡s, es invariante a las transformaciones lineales de los datos, lo que la hace robusta frente a diferencias en la escala de las variables. Este enfoque es especialmente Ãºtil para identificar outliers en conjuntos de datos multivariados, asegurando una detecciÃ³n mÃ¡s confiable de anomalÃ­as en el consumo de energÃ­a elÃ©ctrica. 
 
### AnÃ¡lisis de resultados: 
#### MÃ©tricas de desempeÃ±o de los modelos: 
Para evaluar los modelos de clustering, inicialmente realizamos una comparaciÃ³n entre el Silhouette Score, Davies Bouldin y Calinski Harabaz para los modelos k-Means (KM) y basados en umbrales, considerando cada cliente individualmente. Este tipo de clusterizaciÃ³n nos permite definir un centroide Ã³ptimo, que en este caso corresponde a un factor de potencia de 1 y un desequilibrio de 0. Basados en estos resultados, el modelo KM superÃ³ a los modelos basados en umbrales, con la excepciÃ³n del Silhouette Score, donde fue ligeramente inferior. 

| **Metric**              | **k-Means**        | **Clustering por umbrales**                     |
| ----------------------- | ------------------ | ----------------------------------------------- |
| Silhouette Score        | Â Â Â Â Â Â Â Â Â Â Â Â 0.5578 | Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â 0.5625 |
| Davies-Bouldin Score    | Â Â Â Â Â Â Â Â Â Â Â Â 0.7273 | Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â 1.3404 |
| Calinski-Harabasz Score | Â Â Â 400,465.67      | Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â 135,249.63       |

Tabla 1. ComparaciÃ³n mÃ©tricas modelo K-Means y basado en umbrales. 
 
No obstante, dado que nuestro objetivo es identificar anomalÃ­as, decidimos evaluar tambiÃ©n la densidad, el nÃºmero de datos y la varianza de cada cluster en ambos modelos. Evaluamos la densidad para entender cuÃ¡n dispersos o compactos son los puntos dentro de cada agrupamiento. El nÃºmero de datos nos da una idea del tamaÃ±o del cluster. En condiciones normales, el conjunto de anomalÃ­as tiende a ser mÃ¡s pequeÃ±o, ya que las anomalÃ­as no son tan frecuentes. La varianza nos proporciona una medida de cuÃ¡nto varÃ­an los puntos dentro de cada cluster. Dado que las anomalÃ­as suelen ser puntos que se apartan de la norma, esperarÃ­amos que el agrupamiento de anomalÃ­as presente una mayor varianza. 

**Modelo K-Means**
| **mÃ©trica**  | **Normal**             | **AnomalÃ­a**                                       |
| ------------ | ---------------------- | -------------------------------------------------- |
| Densidad     | Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â 0.13 | Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â 0.19 |
| NÃºmero datos | Â Â Â 327,418.00          | Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â 63,911.00        |
| Varianza     | Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â 0.01 | Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â 0.03 |

**Modelo Basado en Umbrales**
| **mÃ©trica**  | **Normal**             | **AnomalÃ­a**                                       |
| ------------ | ---------------------- | -------------------------------------------------- |
| Densidad     | Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â 0.14 | Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â 0.37 |
| NÃºmero datos | Â Â Â 350,937.00          | Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â 40,392.00        |
| Varianza     | Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â 0.01 | Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â 0.08 |


Tablas 2 y 3. ComparaciÃ³n mÃ©tricas modelo K-Means y basado en umbrales. 

Basados en los resultados de las anteriores tablas, observamos que el mÃ©todo basado en umbrales parece tener una mayor sensibilidad en la detecciÃ³n de anomalÃ­as. Este enfoque mostrÃ³ el conjunto que estÃ¡ mÃ¡s disperso (mayor densidad y varianza) y tiene menor nÃºmero de datos en comparaciÃ³n con k-Means. 

Esto sugiere que cuando los clusters tienen alta varianza, las mÃ©tricas de Silhouette, Davies Bouldin y Calinski Harabaz podrÃ­an no ser suficientes para evaluar la calidad del clustering, ya que estas mÃ©tricas se centran en la cohesiÃ³n de los datos. Por lo tanto, es importante considerar tambiÃ©n otras mÃ©tricas que reflejen la dispersiÃ³n de los datos al evaluar modelos de clustering para la detecciÃ³n de anomalÃ­as. 

Al visualizar la clusterizaciÃ³n K-Means de la imagen 10 y comparar los clusters con el factor de potencia (FP) en el eje x y el desequilibrio de voltaje (DV) en el eje y, podemos validar nuestras hipÃ³tesis. Recordemos que nuestro punto Ã³ptimo, es tener una eficiencia de 1 en el FP y un desequilibrio 0 en el DV, es decir, los datos en condiciones ideales deberÃ­an estar concentrados en la zona inferior derecha de la imagen 10. En esta imagen, correspondiente al Cliente 22 con K-means, que lo escogimos de ejemplo por su gran variabilidad, se observa un cluster (amarillo) de anomalÃ­as claramente definido, donde se consideran anomalÃ­as los valores con un factor de potencia (FP) inferior a 0.65 aproximadamente. Sin embargo, este modelo parece no considerar adecuadamente una cantidad significativa de datos que presentan anomalÃ­as debido a un alto desequilibrio de voltaje (DV), los cuales se encuentran principalmente en la parte superior-derecha del grÃ¡fico. 

 
![Imagen 10](https://github.com/ggomez1803/ElectroDunas/assets/10146054/ee45605f-154b-4247-a53b-fe22838e6443)<br>
Imagen 10. GrÃ¡fico de dispersiÃ³n modelo K-Means Cliente 22 

A diferencia del modelo k-means, el modelo basado en umbrales (imagen 11), que mantiene constante el centroide Ã³ptimo, nos proporciona una mejor visiÃ³n de los datos que se alejan mÃ¡s de este centroide â€œidealâ€ y, por lo tanto, entre mÃ¡s alejados estÃ©n tienen una mayor probabilidad de ser anomalÃ­as. Este modelo utiliza la distancia de Mahalanobis como medida de distancia, la cual, a diferencia de la distancia euclidiana, tiene en cuenta la correlaciÃ³n entre las variables aleatorias. Por lo tanto, para nuestro modelo, fundamentados en los resultados, decidimos optar por los modelos de clusterizaciÃ³n basado en umbrales, dado que consideramos identifican de una mejor manera las anomalÃ­as. 

 ![Imagen 11](https://github.com/ggomez1803/ElectroDunas/assets/10146054/78208824-7a00-4e54-bbc2-5fca37a46967)<br>
Imagen 11. GrÃ¡fico de dispersiÃ³n modelo basado en umbrales Cliente 22 

### Plan de implementaciÃ³n del prototipo: 
Como plan de implementaciÃ³n del prototipo se propone la siguiente infraestructura: 

 ![Imagen 12](https://github.com/ggomez1803/ElectroDunas/assets/10146054/597d6864-b197-4af5-a0fc-60c750eccb18)<br>

A partir de un repositorio de SharePoint se podrÃ¡n cargar los archivos de entrada con los consumos de los diferentes clientes, posteriormente desde un script de Python se leerÃ¡n y procesarÃ¡n los archivos para luego correr el modelo de segmentaciÃ³n para cada cliente, consolidar la informaciÃ³n de los consumos y exportar los datos a otro archivo .csv. Este Ãºltimo archivo .csv serÃ¡ el insumo para poder realizar las grÃ¡ficas de detecciÃ³n de anomalÃ­as por cliente. 

Ahora bien, para facilitar la operabilidad del reporte, se han creado varios scripts de Python que estÃ¡n interconectados entre ellos de la siguiente forma: 

 ![Imagen 13](https://github.com/ggomez1803/ElectroDunas/assets/10146054/56b1c53e-32bb-42a5-8574-e87185e54cd2)<br>

Imagen 13. Estructura de scripts de Python 

Donde en rutas.py se diligencian las rutas de lectura y de exportaciÃ³n de los archivos que se van a trabajar, mientras que en Funciones_Procesamiento.py y Funciones_Cluster.py se encuentran todas las acciones que se realizan a los datos de entrada y donde se cargan los modelos de cluster ya entrenados para poder predecir nuevos datos en el futuro. 
